{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook shows the pretraining of the general source model (GenTL). The paper explains the methodology of the following code. \n",
    "We start by defining a config file, which sets all parameters for training. We have performed a hyperparameter tuning in advance with the results incorporated in the config. \n",
    "\n",
    "For pretraining several building time series are employed, depending on the number of time series included in the folder *source_data_path*. In the paper we used 450 time series, whereas here we use 10 time series for space and computational reasons. If you want to work with the general source model from the paper, this is included under *models*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.preprocessing import *\n",
    "from src.train import train_model\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "source_data_path = os.path.join(\"data\", \"sources\")\n",
    "\n",
    "# Config for the pretraining\n",
    "config = {\n",
    "    \"lookback\": 96,\n",
    "    \"forecast_horizon\": 16,\n",
    "    \"num_layers\": 3,\n",
    "    \"hidden_size\": 125,\n",
    "    \"batch_size\": 256,\n",
    "    \"optimizer\": optim.Adam,\n",
    "    \"learning_rate\": 0.0012,\n",
    "    \"epochs\": 20,\n",
    "    \"dropout\": 0.0,\n",
    "    \"loss_function\": nn.MSELoss(),\n",
    "    \"dataloader_shuffle\": True,\n",
    "    \"train_split\": 0.7,\n",
    "    \"val_split\": 0.15,\n",
    "    \"data_path\": source_data_path,\n",
    "    \"target_name\": [\"thermalZoneTAir\"],\n",
    "    \"feature_cols\": [\"u\", \"weaBusHDifHor\", \"weaBusHDirNor\", \"weaBusTDryBul\", \"thermalZoneTAir\"],\n",
    "    \"dataframe_limit\": 35037,\n",
    "    \"use_amp\": False,\n",
    "    \"model_name\": \"gen_model_on_10_sources\",\n",
    "    \"scaler_name\": \"sc_gen_model_on_10_sources\",\n",
    "    \"scale_target\": True,\n",
    "    \"save_best_val\": True,\n",
    "    \"exclude\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda to train the model.\n",
      "Make train test split\n",
      "Make train test split\n",
      "Make train test split\n",
      "Make train test split\n",
      "Make train test split\n",
      "Make train test split\n",
      "Make train test split\n",
      "Make train test split\n",
      "Make train test split\n",
      "Make train test split\n",
      "11:17:54 Epoch 0: Train RMSE: 2.3241941928863525; Val RMSE: 2.3064005374908447\n",
      "--> RMSE decreased - model will be saved as best model.\n",
      "11:18:16 Epoch 1: Train RMSE: 2.632235288619995; Val RMSE: 2.576043128967285\n",
      "11:18:37 Epoch 2: Train RMSE: 2.0661518573760986; Val RMSE: 2.081904888153076\n",
      "--> RMSE decreased - model will be saved as best model.\n",
      "11:18:59 Epoch 3: Train RMSE: 1.8086276054382324; Val RMSE: 1.8732054233551025\n",
      "--> RMSE decreased - model will be saved as best model.\n",
      "11:19:21 Epoch 4: Train RMSE: 1.6311028003692627; Val RMSE: 1.6530243158340454\n",
      "--> RMSE decreased - model will be saved as best model.\n",
      "11:19:43 Epoch 5: Train RMSE: 1.6390013694763184; Val RMSE: 1.6304876804351807\n",
      "--> RMSE decreased - model will be saved as best model.\n",
      "11:20:05 Epoch 6: Train RMSE: 1.5980743169784546; Val RMSE: 1.5824832916259766\n",
      "--> RMSE decreased - model will be saved as best model.\n",
      "11:20:26 Epoch 7: Train RMSE: 1.4097614288330078; Val RMSE: 1.489851951599121\n",
      "--> RMSE decreased - model will be saved as best model.\n",
      "11:20:47 Epoch 8: Train RMSE: 1.5704649686813354; Val RMSE: 1.8067280054092407\n",
      "11:21:08 Epoch 9: Train RMSE: 1.3837494850158691; Val RMSE: 1.4300121068954468\n",
      "--> RMSE decreased - model will be saved as best model.\n",
      "11:21:30 Epoch 10: Train RMSE: 1.5049870014190674; Val RMSE: 1.5677562952041626\n",
      "11:21:47 Epoch 11: Train RMSE: 1.4630793333053589; Val RMSE: 1.565143346786499\n",
      "11:22:05 Epoch 12: Train RMSE: 1.2995635271072388; Val RMSE: 1.3982306718826294\n",
      "--> RMSE decreased - model will be saved as best model.\n",
      "11:22:23 Epoch 13: Train RMSE: 1.28312349319458; Val RMSE: 1.4278371334075928\n",
      "11:22:40 Epoch 14: Train RMSE: 1.2643312215805054; Val RMSE: 1.4265834093093872\n",
      "11:22:58 Epoch 15: Train RMSE: 1.5074632167816162; Val RMSE: 1.5689921379089355\n",
      "11:23:16 Epoch 16: Train RMSE: 1.3441239595413208; Val RMSE: 1.3790138959884644\n",
      "--> RMSE decreased - model will be saved as best model.\n",
      "11:23:34 Epoch 17: Train RMSE: 1.257165551185608; Val RMSE: 1.4062539339065552\n",
      "11:23:51 Epoch 18: Train RMSE: 1.187013864517212; Val RMSE: 1.253718614578247\n",
      "--> RMSE decreased - model will be saved as best model.\n",
      "11:24:09 Epoch 19: Train RMSE: 1.2734133005142212; Val RMSE: 1.3004077672958374\n"
     ]
    }
   ],
   "source": [
    "# Train the model with this config on all sources.\n",
    "result_dict, test_dataloader, scalers, best_val_errors = train_model(config, \"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gentl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
